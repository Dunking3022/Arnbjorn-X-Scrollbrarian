{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b1b349",
   "metadata": {},
   "source": [
    "# Customized Elder Scrolls ChatBot using OpenAI Text Embedding\n",
    "\n",
    "In this project, I've decided to use all the text from the Elder Scrolls Series and use it to get accurate context based responses from OpenAI's API. \n",
    "\n",
    "The Dataset that we are using is borrowed from https://github.com/jd7h/sentiment-lexicon-skyrim/\n",
    "\n",
    "\n",
    "### Installation of necessary libraries and modules\n",
    "\n",
    "We ensure that all the necessary libraries are installed and if they aren't, this step installs all of them for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af431bfb",
   "metadata": {},
   "source": [
    "### Importing the libraries inside our python file\n",
    "\n",
    "All the libraries are imported into our python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca6b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import time\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea553e52",
   "metadata": {},
   "source": [
    "### Getting the OpenAI API key from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ae38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai.api_key = input()\n",
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820fade4",
   "metadata": {},
   "source": [
    "### Loading and formatting the data\n",
    "\n",
    "The JSON file is opened and converted to a pandas dataframe that is then further used to remove unwanted entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e45579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = json.load(open(\"TheElderScrollsBooksDataset.json\", encoding='ascii')) # https://github.com/jd7h/sentiment-lexicon-skyrim/\n",
    "df = pd.DataFrame(scripts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7676383",
   "metadata": {},
   "source": [
    "As the dataset includes books from games from multiple Elder Scroll games, we keep the entries for books from Skyrim and exclude all other books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8c7d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[(df['game'] == \"Skyrim\")]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb36a50",
   "metadata": {},
   "source": [
    "Optionally, we can exclude all the books where the author is \"Anonymous\" if we want to reduce the size of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee53be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df['author'] != \"Anonymous\"]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e8a795",
   "metadata": {},
   "source": [
    "### Tokenizing the text from the books and converting it to chunks\n",
    "\n",
    "Next, we define a chunk size, overlap size and tokenize all the entries from our now modified dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cee8fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Books from Elder Scrolls V Skyrim: 756\n",
      "Total Token Size of All the Books : 436335\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 1000\n",
    "OVERLAP = 20\n",
    "\n",
    "skyrimBooks = 0\n",
    "skyrimBookTokens = []\n",
    "for x in (df['text']):\n",
    "    skyrimBookTokens += x.split()\n",
    "    skyrimBooks+=1;\n",
    "print(\"Total Books from Elder Scrolls V Skyrim:\",skyrimBooks)\n",
    "print(\"Total Token Size of All the Books :\",len(skyrimBookTokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aef35e",
   "metadata": {},
   "source": [
    "Once that is done, we convert these tokens to chunks that we will send to OpenAI's API to be converted into text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2719e961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Chunks :  446\n"
     ]
    }
   ],
   "source": [
    "chunks = [skyrimBookTokens[i:i+CHUNK_SIZE] for i in range(0, len(skyrimBookTokens), CHUNK_SIZE-OVERLAP)]\n",
    "cdf = pd.DataFrame(columns=['chunk', 'gpt_raw', 'embedding'])\n",
    "print(\"Total Number of Chunks : \",len(chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc10177",
   "metadata": {},
   "source": [
    "Alternatively, we can pickle our chunks for later use as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a727aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully exported to pickledSkyrimTextChunks1.pkl\n"
     ]
    }
   ],
   "source": [
    "pickledChunkPath = 'pickledSkyrimTextChunks.pkl'\n",
    "inc = 1\n",
    "while(os.path.exists(pickledChunkPath)):\n",
    "    pickledChunkPath = pickledChunkPath[0:23] + str(inc) + pickledChunkPath[-4::]\n",
    "    inc+=1\n",
    "with open(pickledChunkPath, 'wb') as f:\n",
    "    pickle.dump(chunks, f)\n",
    "print(\"DataFrame successfully exported to\",pickledChunkPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207e576",
   "metadata": {},
   "source": [
    "### Sending Chunks to OpenAI's API\n",
    "\n",
    "Now that our chunks are finallized, we can send them to OpenAI's API which will return us with the text embeddings for all the tokens in our chunks.\n",
    "\n",
    "If you do not have a subscription for OpenAI's services, you can only send maximum of 60 request in a minute which is why we initialize a variable called <b><i>chunksSent</i></b> which keeps tracks of how many requests we have made and if that is exceeded by 50, we halt the program for 1 minute and then reset our chunksSent Variable and continue sending chunks until all the chunks are succesfully sent and we recieve the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e88d62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447  chunks succesfully embedded!\n"
     ]
    }
   ],
   "source": [
    "chunksSent=0\n",
    "for chunk in chunks:\n",
    "    if(chunksSent>50):\n",
    "        time.sleep(60)\n",
    "        chunksSent = 0\n",
    "    f = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=\" \".join(chunk),\n",
    "    )\n",
    "    cdf.loc[len(cdf.index)] = (chunk, f, np.array(f['data'][0]['embedding']))\n",
    "    chunksSent+=1\n",
    "print(len(cdf),\" chunks succesfully embedded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a53068",
   "metadata": {},
   "source": [
    "### Reviewing our new dataframe\n",
    "\n",
    "We have successfully embedded all the chunks and now we can review if the dataframe is looking good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "023b5ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>gpt_raw</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[16, Accords, of, Madness,, v., VI, Hircine's,...</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>[0.00324949505738914, -0.008569796569645405, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[was, no, fear,, for, he, had, faith, that, hi...</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>[-0.0006086188950575888, -0.01804208941757679,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[among, his, tribe., On, a, blustery, day,, he...</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>[-0.0032683517783880234, -0.0243468526750803, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[to, push, past, him,, Lord, Sheogorath, spoke...</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>[0.0012960234889760613, -0.012394634075462818,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[it, was, not, until, well, after, noon, that,...</td>\n",
       "      <td>{'object': 'list', 'data': [{'object': 'embedd...</td>\n",
       "      <td>[0.009688128717243671, -0.023770440369844437, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "1  [16, Accords, of, Madness,, v., VI, Hircine's,...   \n",
       "2  [was, no, fear,, for, he, had, faith, that, hi...   \n",
       "3  [among, his, tribe., On, a, blustery, day,, he...   \n",
       "4  [to, push, past, him,, Lord, Sheogorath, spoke...   \n",
       "5  [it, was, not, until, well, after, noon, that,...   \n",
       "\n",
       "                                             gpt_raw  \\\n",
       "1  {'object': 'list', 'data': [{'object': 'embedd...   \n",
       "2  {'object': 'list', 'data': [{'object': 'embedd...   \n",
       "3  {'object': 'list', 'data': [{'object': 'embedd...   \n",
       "4  {'object': 'list', 'data': [{'object': 'embedd...   \n",
       "5  {'object': 'list', 'data': [{'object': 'embedd...   \n",
       "\n",
       "                                           embedding  \n",
       "1  [0.00324949505738914, -0.008569796569645405, -...  \n",
       "2  [-0.0006086188950575888, -0.01804208941757679,...  \n",
       "3  [-0.0032683517783880234, -0.0243468526750803, ...  \n",
       "4  [0.0012960234889760613, -0.012394634075462818,...  \n",
       "5  [0.009688128717243671, -0.023770440369844437, ...  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ce050",
   "metadata": {},
   "source": [
    "### Storing our dataframe as a pickle file for later use\n",
    "\n",
    "Optionally, we can store our dataframe as a pickle file which we can load later so we don't have to perform the text embedding every time we reload our notebook.  \n",
    "\n",
    "I've also included a short code that checks if there is already any existing pickle file and if there is, a new one is created so we don't end up overwriting our previous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9361c16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully exported to pickledSkyrimTextEmbedding2.pkl\n"
     ]
    }
   ],
   "source": [
    "pickledFilePath = 'pickledSkyrimTextEmbedding.pkl'\n",
    "inc = 1\n",
    "while(os.path.exists(pickledFilePath)):\n",
    "    pickledFilePath = pickledFilePath[0:26] + str(inc) + pickledFilePath[-4::]\n",
    "    inc+=1\n",
    "cdf.to_pickle(pickledFilePath)\n",
    "print(\"DataFrame successfully exported to\",pickledFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf00387",
   "metadata": {},
   "source": [
    "### Loading previously pickled dataframe\n",
    "\n",
    "Now we can load our dataframe fromt the pickle file and utilize it to calculate cosine similiarity with our input.\n",
    "\n",
    "We can modify the value in <i>pd.read_pickle(fileName)</i> to specify which pickle file is to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b700edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 chunk  \\\n",
      "1    [16, Accords, of, Madness,, v., VI, Hircine's,...   \n",
      "2    [was, no, fear,, for, he, had, faith, that, hi...   \n",
      "3    [among, his, tribe., On, a, blustery, day,, he...   \n",
      "4    [to, push, past, him,, Lord, Sheogorath, spoke...   \n",
      "5    [it, was, not, until, well, after, noon, that,...   \n",
      "..                                                 ...   \n",
      "442  [of, the, forest, dwelling, mages, in, Summers...   \n",
      "443  [didn't, know, any, better., Incense, burned, ...   \n",
      "444  [out, of, the, shop, and, down, the, road, to,...   \n",
      "445  [forest, people, who, were, torn, between, man...   \n",
      "446  [Two, fortnights, passed, without, relief,, un...   \n",
      "\n",
      "                                               gpt_raw  \\\n",
      "1    {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "2    {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "3    {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "4    {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "5    {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "..                                                 ...   \n",
      "442  {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "443  {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "444  {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "445  {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "446  {'object': 'list', 'data': [{'object': 'embedd...   \n",
      "\n",
      "                                             embedding  \n",
      "1    [0.00324949505738914, -0.008569796569645405, -...  \n",
      "2    [-0.0006086188950575888, -0.01804208941757679,...  \n",
      "3    [-0.0032683517783880234, -0.0243468526750803, ...  \n",
      "4    [0.0012960234889760613, -0.012394634075462818,...  \n",
      "5    [0.009688128717243671, -0.023770440369844437, ...  \n",
      "..                                                 ...  \n",
      "442  [0.024210412055253983, 0.0013219235697761178, ...  \n",
      "443  [0.006533252075314522, 0.0065514100715518, 0.0...  \n",
      "444  [0.01662762090563774, -0.0004964537220075727, ...  \n",
      "445  [0.0018058957066386938, -0.01339358277618885, ...  \n",
      "446  [-0.010087004862725735, -0.029654692858457565,...  \n",
      "\n",
      "[446 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pickled_df = pd.read_pickle('pickledSkyrimTextEmbedding1.pkl')\n",
    "print(pickled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397f427",
   "metadata": {},
   "source": [
    "### Getting Query from the user, calculating cosine similiarity and getting a response\n",
    "\n",
    "Next we ask the user to input the query that is to be used to be utilized for getting a response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52b775aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Query : Which is the most hostile god\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter Query : \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42aa54e",
   "metadata": {},
   "source": [
    "Once we have the query, we create a text embedding for our query and calculate the cosine similiarty with our previously calculated text embedding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2317a224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Successfully Recieved!\n"
     ]
    }
   ],
   "source": [
    "f = openai.Embedding.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=query\n",
    ")\n",
    "query_embedding = np.array(f['data'][0]['embedding'])\n",
    "\n",
    "similarity = []\n",
    "for arr in pickled_df['embedding'].values:\n",
    "    similarity.extend(cosine_similarity(query_embedding.reshape(1, -1), arr.reshape(1, -1)))\n",
    "context_chunk = chunks[np.argmax(similarity)]\n",
    "\n",
    "query_to_send = \"CONTEXT: \" + \" \".join(context_chunk) + \"\\n\\n\" + query\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt= query_to_send,\n",
    "  max_tokens=2000,\n",
    "  temperature=0\n",
    ")\n",
    "print(\"Response Successfully Recieved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c23150",
   "metadata": {},
   "source": [
    "Finally, we print the response that we have recieved from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "008dacd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in Tamrielic mythic tradition?\n",
      "\n",
      "Molag Bal (God of Schemes, King of Rape): Daedric power of much importance in Morrowind. There, he is always the archenemy of Boethiah, the Prince of Plots. He is the main source of the obstacles to the Dunmer (and preceding Chimer) people. In the legends, Molag Bal always tries to upset the bloodlines of Houses or otherwise ruin Dunmeri 'purity'. A race of supermonsters, said to live in Molag Amur, are the result of his seduction of Vivec during the previous era.\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
